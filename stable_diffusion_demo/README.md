# Stable Diffusion Demo

A browser-based demonstration of Stable Diffusion 1.5 image generation using ONNX Runtime Web. This project exports Stable Diffusion models to ONNX format and runs inference in the browser with step-by-step visualization.

## Features

- Export Stable Diffusion 1.5 models (text encoder, UNet, VAE decoder) to ONNX
- Browser-based inference using ONNX Runtime Web
- Real-time step-by-step visualization of image generation
- Interactive UI with customizable prompts, steps, and guidance scale

## Setup

### 1. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 2. Export Models to ONNX

Run the export script to convert the Stable Diffusion models to ONNX format:

```bash
python export_to_onnx.py --output-dir models
```

This will:
- Download Stable Diffusion 1.5 from HuggingFace (if not already cached)
- Export the text encoder, UNet, and VAE decoder to ONNX
- Save the models in the `models/` directory

**Note:** 
- The export process may take several minutes and requires significant disk space (~2-3 GB for the models)
- The `models/` directory will be created automatically if it doesn't exist
- You need a stable internet connection to download the model from HuggingFace

### 3. Download Tokenizer Files (Optional but Recommended)

For better text encoding, download the tokenizer files:

```bash
python download_tokenizer.py --output-dir models
```

The demo will work without these files using a simplified tokenizer, but results may vary. The tokenizer files improve prompt understanding and generation quality.

### 4. Serve the Web Application

You need to serve the files via HTTP (not file://) due to CORS restrictions. You can use:

**Python:**
```bash
cd stable_diffusion_demo
python -m http.server 8000
```

**Node.js:**
```bash
npx http-server -p 8000
```

Then open `http://localhost:8000` in your browser.

## Usage

1. Open the web application in your browser
2. Wait for models to load (this may take a minute)
3. Enter a text prompt
4. Adjust the number of steps (default: 20) and guidance scale (default: 7.5)
5. Click "Generate" to start the denoising process
6. Watch as the image is generated step-by-step!

## Project Structure

```
stable_diffusion_demo/
├── export_to_onnx.py      # Python script to export models
├── requirements.txt        # Python dependencies
├── index.html             # Main HTML file
├── js/
│   ├── tokenizer.js       # Text tokenizer implementation
│   ├── diffusion.js       # Stable Diffusion inference logic
│   └── main.js            # Application entry point
├── models/                # ONNX models (generated by export script)
└── README.md              # This file
```

## Technical Details

### Model Export

The export script uses PyTorch's ONNX exporter to convert:
- **Text Encoder**: CLIP text encoder that converts text prompts to embeddings
- **UNet**: The denoising model that predicts noise at each step
- **VAE Decoder**: Converts latent representations to pixel images

### Inference Process

1. **Text Encoding**: The prompt is tokenized and encoded using the text encoder
2. **Noise Initialization**: Random noise is generated in the latent space
3. **Denoising Loop**: For each step:
   - The UNet predicts the noise
   - The latent is updated using a scheduler (DDIM)
   - The current state is decoded and displayed
4. **Final Decode**: The final latent is decoded to produce the output image

### Limitations

- The current implementation uses a simplified tokenizer (for production, use the full CLIP tokenizer)
- Classifier-free guidance is simplified (full implementation would require unconditional predictions)
- The scheduler is a basic DDIM implementation
- Model loading and inference can be slow in the browser (consider using WebGPU backend for better performance)

## Performance Notes

- Model files are large (~500MB-1GB each), so initial loading takes time
- Inference runs on CPU (WASM backend) by default, which is slower than GPU
- For better performance, consider:
  - Using ONNX Runtime Web with WebGPU backend
  - Quantizing models to reduce size
  - Using a CDN for model files

## License

This project is for educational/demonstration purposes. Stable Diffusion models are subject to their respective licenses from Stability AI and HuggingFace.
